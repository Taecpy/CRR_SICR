{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = 'data_input\\\\SME1\\\\'\n",
    "path_2 = 'data_input\\\\SME2\\\\'\n",
    "path_3 = 'data_input\\\\SME3\\\\'\n",
    "path_c = 'data_input\\\\corp\\\\'\n",
    "path_m = 'data_input\\\\maunal\\\\'\n",
    "path_CR = 'data_input\\\\CR\\\\'\n",
    "path_T9 = 'data_input\\\\TFRS9\\\\'\n",
    "output =  'Output\\\\'\n",
    "mapping = 'Mapping\\\\'\n",
    "on_process = 'data_Process\\\\'\n",
    "data_revised = 'data_revised\\\\'\n",
    "cbs_performance = 'data_input\\CBS_performance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(path_m)\n",
    "# os.mkdir(process)\n",
    "# os.mkdir(data_revised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start on data input for concat ALL data per year export to on process\n",
    "## on-process  for cleansing data per mapping file\n",
    "## export to data revised for CRR SICR \n",
    "## CRR SICR define G/B by performance condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'example Class'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example os.path.join\n",
    "# path = os.path.join(\"user\", \"admin\", \"data\", \"demo.txt\")\n",
    "# print(path)\n",
    "\n",
    "# ML_infra = pd.concat(a, ignore_index=True)\n",
    "# ML_infra.dropna(how='all',inplace=True)\n",
    "# ML_infra.reset_index(inplace=True,drop=True)\n",
    "# ML_commu = pd.concat(b, ignore_index=True)\n",
    "# ML_commu.dropna(how='all',inplace=True)\n",
    "# ML_commu.reset_index(inplace=True,drop=True)\n",
    "# ML_energy = pd.concat(c, ignore_index=True)\n",
    "# ML_energy.dropna(how='all',inplace=True)\n",
    "# ML_energy.reset_index(inplace=True,drop=True)                               \n",
    "# ML_Serv = pd.concat(d, ignore_index=True)\n",
    "# ML_Serv.dropna(how='all',inplace=True)\n",
    "# ML_Serv.reset_index(inplace=True,drop=True) \n",
    "# ML_indust = pd.concat(e, ignore_index=True)\n",
    "# ML_indust.dropna(how='all',inplace=True)\n",
    "# ML_indust.reset_index(inplace=True,drop=True) \n",
    "# ML_Commerce = pd.concat(f, ignore_index=True)\n",
    "# ML_Commerce.dropna(how='all',inplace=True)\n",
    "# ML_Commerce.reset_index(inplace=True,drop=True) \n",
    "# PropertyIn = pd.concat(g, ignore_index=True)\n",
    "# PropertyIn.dropna(how='all',inplace=True)\n",
    "# PropertyIn.reset_index(inplace=True,drop=True) \n",
    "# PropertyDe = pd.concat(h, ignore_index=True)\n",
    "# PropertyDe.dropna(how='all',inplace=True)\n",
    "# PropertyDe.reset_index(inplace=True,drop=True)\n",
    "# Hire = pd.concat(i, ignore_index=True)\n",
    "# Hire.dropna(how='all',inplace=True)\n",
    "# Hire.reset_index(inplace=True,drop=True) \n",
    "# operat = pd.concat(j, ignore_index=True)\n",
    "# operat.dropna(how='all',inplace=True)\n",
    "# operat.reset_index(inplace=True,drop=True) \n",
    "# S_serv = pd.concat(k, ignore_index=True)\n",
    "# S_serv.dropna(how='all',inplace=True)\n",
    "# S_serv.reset_index(inplace=True,drop=True)\n",
    "# S_Commerce = pd.concat(l, ignore_index=True)\n",
    "# S_Commerce.dropna(how='all',inplace=True)\n",
    "# S_Commerce.reset_index(inplace=True,drop=True) \n",
    "# S_indust = pd.concat(m, ignore_index=True)\n",
    "# S_indust.dropna(how='all',inplace=True)\n",
    "# S_indust.reset_index(inplace=True,drop=True) \n",
    "\n",
    "'''test loop'''\n",
    "# for i_p in all_path:\n",
    "#     filenames = glob.glob(i_p + \"/*.xlsx\")\n",
    "#     filenames\n",
    "#     # for loop fine name excel_sheets \n",
    "#     for i_f in filenames:\n",
    "#         xl = pd.ExcelFile(i_f)\n",
    "#         xl.sheet_names\n",
    "#     # for loop read file and concat all file\n",
    "#         for i_s in  xl.sheet_names :\n",
    "#             print(i_p,i_f,i_s)\n",
    "\n",
    "'''example Class'''\n",
    "# class ReturnValue(obj):\n",
    "#        def __init__(self, y0, y1, y2):\n",
    "#       self.y0 = y0\n",
    "#       self.y1 = y1\n",
    "#       self.y2 = y2\n",
    "\n",
    "# def g(x):\n",
    "#    y0 = x + 1\n",
    "#    y1 = x * 3\n",
    "#    y2 = y0 ** 3\n",
    "#    return ReturnValue (y0, y1, y2)\n",
    "\n",
    "'''mutiple valiable in one loop'''\n",
    "# ML_infra,ML_commu,ML_energy,ML_Serv,ML_indust,ML_Commerce,PropertyIn,PropertyDe,Hire,operat,S_serv,S_Commerce,S_indust =  pd.concat([a] ,[b] ,[c] ,[d] ,[e] ,[f ],[g] ,[h] ,[i ],[j] ,[k ],[l] ,[m],ignore_index=True)\n",
    "# def to_Fdata(tool,df):\n",
    "#     for (i_1,i_2) in zip(tool,list_df) :\n",
    "#         i_1 = pd.concat(i_2, ignore_index=True)\n",
    "#         i_1.dropna(how='all',inplace=True)\n",
    "#         i_1.reset_index(inplace=True,drop=True) \n",
    "#         return i_1\n",
    "\n",
    "'''add performance'''\n",
    "# def func(df):\n",
    "#     # create empty list for concat DataFrame\n",
    "#     df_list = []\n",
    "\n",
    "#     # get unique value for Map\n",
    "#     cust_id = [750903011]\n",
    "#     # cust_id = df['CUST_ID'].unique()[0:1]\n",
    "#     # cust_id = df['CUST_ID'].unique()\n",
    "\n",
    "#     \"\"\" Loop procress for create 12 months window performance default\"\"\"\n",
    "#     for i in cust_id:\n",
    "#         # map each CID\n",
    "#         df_i = df[df['CUST_ID'].isin([i])]\n",
    "\n",
    "#         # select start date for window performance\n",
    "#         df_i = df_i[df_i['AS_OF_DATE'] >= df_i['วันที่ประเมิน'].unique()[0]]\n",
    "\n",
    "#         # create field 'Performance' by \"AS_OF_DATE\" minus \"Review_Date\"\n",
    "#         df_i['Performance'] = df_i['AS_OF_DATE'].dt.to_period('M').astype('int64') - df_i['วันที่ประเมิน'].dt.to_period('M').astype('int64')\n",
    "        \n",
    "#         # cut tail, not exceed 12 months\n",
    "#         df_i = df_i[df_i['Performance'] <= 12] \n",
    "#         # fill NA\n",
    "#         df_i.fillna({'NPF_FLAG':'N'}, inplace=True)\n",
    "\n",
    "#         # create field 'FlagDef' for groupby\n",
    "#         df_i['FlagDef'] = df_i['NPF_FLAG'].apply(lambda x: 0 if x == 'N' else 1)\n",
    "\n",
    "#         # append to list\n",
    "#         df_list.append(df_i)\n",
    "\n",
    "#     return df_list\n",
    "\n",
    "# df63_se_grp = df63_se_def.groupby('CUST_ID')[['FlagDef']].sum()\n",
    "# df63_se_grp['FlagGB'] = df63_se_grp['FlagDef'].apply(lambda x : 'Good' if x == 0 else 'Bad')\n",
    "# df63_se_grp\n",
    "\n",
    "'''mapping performance 12 month'''\n",
    "# '''ของจริงต้องใช้ข้อมูลทั้งหมดที่ผ่านการ clean อีกรอบ (CRR_SICR)'''\n",
    "# df_ex = pd.read_excel('backup\\CRR_SICR_เเก้ไขส่งให้พี่เคี้ยง.xlsx')\n",
    "# test = map_performance(df_ex)\n",
    "# test.to_excel(os.path.join(output,'test.xlsx'),index=False)\n",
    "# test.groupby('Grade_current').count().sort_values(by='Grade_current',ascending=True)\n",
    "'''remove dupe performance'''\n",
    "# df_p.groupby('AS_OF_DATE').count()\n",
    "# df_p = df_p.drop(columns='Unnamed: 0')\n",
    "# df_p.drop_duplicates(subset=['ACC_ID','AS_OF_DATE'],inplace=True)\n",
    "# df_p.to_csv('{}'.format(filenames),index=False,sep='\\t')\n",
    "\n",
    "'''mapping performance for define G/B'''\n",
    "# list_date = {'31 ธ.ค.  2021':'2021-12-31', '30 พ.ย.  2021':'2021-11-30', '31 ต.ค.  2021':'2021-10-31', '30 ก.ย.  2021':'2021-09-30',\n",
    "#        '31 ส.ค.  2021':'2021-08-31', '31 ก.ค.  2021':'2021-07-31', '30 มิ.ย. 2021':'2021-06-30', '31 พ.ค.  2021':'2021-05-31',\n",
    "#        '30 เม.ย. 2021':'2021-04-30', '31 ม.ค.  2020':'2020-01-31', '29 ก.พ.  2020':'2020-02-29', '31 มี.ค. 2020':'2020-03-31',\n",
    "#        '30 เม.ย. 2020':'2020-04-30', '31 พ.ค.  2020':'2020-05-31', '30 มิ.ย. 2020':'2020-06-30', '31 ก.ค.  2020':'2020-07-31',\n",
    "#        '31 ส.ค.  2020':'2020-08-31', '30 ก.ย.  2020':'2020-09-30', '31 ต.ค.  2020':'2020-10-31', '30 พ.ย.  2020':'2020-11-30',\n",
    "#        '31 ธ.ค.  2020':'2020-12-31', '31 ม.ค.  2021':'2021-01-31', '28 ก.พ.  2021':'2021-02-28', '31 มี.ค. 2021':'2021-03-31',\n",
    "#        '28 ก.พ.  2022':'2022-02-28', '31 ม.ค.  2022':'2022-01-31', '31 ม.ค.  2023':'2023-01-31', '31 มี.ค. 2022':'2022-03-31',\n",
    "#        '31 ธ.ค.  2022':'2022-12-31', '31 พ.ค.  2022':'2022-05-31', '30 มิ.ย. 2022':'2022-06-30', '31 ก.ค.  2022':'2022-07-31',\n",
    "#        '31 ส.ค.  2022':'2022-08-31', '30 ก.ย.  2022':'2022-09-30', '30 เม.ย. 2022':'2022-04-30', '31 ต.ค.  2022':'2022-10-31',\n",
    "#        '30 พ.ย.  2022':'2022-11-30', '28 ก.พ.  2023':'2023-02-28', '31 มี.ค. 2023':'2023-03-31', '30 เม.ย. 2023':'2023-04-30',\n",
    "#        '31 พ.ค.  2023':'2023-05-31', '30 มิ.ย. 2023':'2021-06-30', '30 ก.ย.  2023':'2023-09-30', '31 ส.ค.  2023':'2023-08-31',\n",
    "#        '31 ก.ค.  2023':'2023-07-31', '31 ต.ค.  2023':'2023-10-31', '30 พ.ย.  2023':'2023-11-30'}\n",
    "# df_p['AS_OF_DATE'].replace(list_date,inplace=True)\n",
    "# df_p.drop_duplicates(subset=['CUST_ID','AS_OF_DATE'],inplace=True)\n",
    "# # i = df_ex['Customer Number'].unique()[-30]\n",
    "# i = 750441945\n",
    "# df = df_p[df_p['CUST_ID'].isin([i])]\n",
    "# df2 = df_ex[df_ex['Customer Number'].isin([i])]\n",
    "# df2['วันที่ประเมิน_originate'] = pd.to_datetime(df2['วันที่ประเมิน_originate'])\n",
    "# df['AS_OF_DATE'] = pd.to_datetime(df['AS_OF_DATE'])\n",
    "# df_3 = df[df['AS_OF_DATE'] >= df2['วันที่ประเมิน_originate'].unique()[0]]\n",
    "# df2['วันที่ประเมิน_originate'].unique()\n",
    "\n",
    "\n",
    "\n",
    "# filenames = glob.glob(cbs_performance + \"/*.txt\")[-1]\n",
    "# df_p = pd.read_csv(filenames,sep='\\t')\n",
    "# df_p['AS_OF_DATE'].replace(list_date,inplace=True)\n",
    "# df_p.drop_duplicates(subset=['CUST_ID','AS_OF_DATE'],inplace=True)\n",
    "# # i = df_ex['Customer Number'].unique()[-30]\n",
    "# i = 750441945\n",
    "# df = df_p[df_p['CUST_ID'].isin([i])]\n",
    "# df2 = df_ex[df_ex['Customer Number'].isin([i])]\n",
    "# df2['วันที่ประเมิน_originate'] = pd.to_datetime(df2['วันที่ประเมิน_originate'])\n",
    "# df['AS_OF_DATE'] = pd.to_datetime(df['AS_OF_DATE'])\n",
    "# df_3 = df[df['AS_OF_DATE'] >= df2['วันที่ประเมิน_originate'].unique()[0]]\n",
    "# df_3.sort_values(by=['AS_OF_DATE'])\n",
    "# df_3['Months'] = df_3['AS_OF_DATE'].dt.to_period('M').astype('int64') - df_3['วันที่ประเมิน_originate'].dt.to_period('M').astype('int64')\n",
    "# df_p['NPF_FLAG'] = df_p['NPF_FLAG'].apply(lambda x : 1 if x =='Y' else 0)\n",
    "# df_ex = df_ex.dropna(subset=['วันที่ประเมิน_originate'])\n",
    "\n",
    "'''for tracking review CRR'''\n",
    "#select path\n",
    "# all_path = [path_1,path_2,path_3,path_c,path_m,path_CR]\n",
    "# # all_path = [path_c]\n",
    "# # file_2563 = check_fileCRR(all_path,'2563')\n",
    "# # file_2564 = check_fileCRR(all_path,'2564')\n",
    "# file_2565 = check_fileCRR(all_path,'2565')\n",
    "# # file_2566 = check_fileCRR(all_path,'2023')\n",
    "# #for export file\n",
    "# # export_file(file_2563,'file_2563_C')\n",
    "# # export_file(file_2564,'file_2564_C')\n",
    "# export_file(file_2565,'file_2565')\n",
    "# # export_file(file_2566,'file_2566_C')\n",
    "# all_path = [path_1,path_2,path_3,path_c,path_m]\n",
    "# # list_CRR = prepare_fileCRR(all_path,'2563')\n",
    "# # export_excel(list_CRR,'ALL_CRR_2563',on_process)\n",
    "# # list_CRR = prepare_fileCRR(all_path,'2564')\n",
    "# # export_excel(list_CRR,'ALL_CRR_2564',on_process)\n",
    "# # list_CRR = prepare_fileCRR(all_path,'2565')\n",
    "# # export_excel(list_CRR,'ALL_CRR_2565',on_process)\n",
    "# list_CRR = prepare_fileCRR(all_path,'all')\n",
    "# export_excel(list_CRR,'ALL_CRR',on_process)\n",
    "\n",
    "'''clean data'''\n",
    "# # all_path = [on_process]\n",
    "# # file = check_fileCRR(all_path,'all')\n",
    "# # # export_file(file,'file')\n",
    "# # file.to_excel('test.xlsx')\n",
    "# # replace date manual by excel_file\n",
    "# all_path = [on_process]\n",
    "# data_all = mappind_data(all_path)\n",
    "# export_excel(data_all,'ALL_CRR',data_revised)\n",
    "# # data_all[0][['วันที่ประเมิน']].isnull().sum()\n",
    "\n",
    "# dt.date.today().strftime(\"%y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ใช้ทำข้อมูล\n",
    "# find data in path\n",
    "def prepare_fileCRR(path,year):\n",
    "    # mutiple list in one line\n",
    "    # list_a, list_b = [], []\n",
    "    a ,b ,c ,d ,e ,f ,g ,h ,i ,j ,k ,l ,m = [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "    for i_p in path:\n",
    "        filenames = glob.glob(i_p + \"/*.xlsx\")\n",
    "        filenames\n",
    "        # for loop find name excel_sheets\n",
    "        for i_f in filenames:\n",
    "            if year in i_f or year == 'all':\n",
    "                xl = pd.ExcelFile(i_f)\n",
    "        # for loop read file and concat all file\n",
    "                for i_s in  xl.sheet_names:\n",
    "                    print('read file = {} ,sheet_name = {}'.format(i_f,i_s))\n",
    "                    # M & L Infrastructure sheets\n",
    "                    if (i_s == 'M & L Infrastructure'):\n",
    "                        # print(i_s,i_f)\n",
    "                        a.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al'))                \n",
    "                    # M & L Communication sheets\n",
    "                    if (i_s == 'M & L Communication'):\n",
    "                        b.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al'))      \n",
    "                    # M & L Energy sheets\n",
    "                    if (i_s == 'M & L Energy'):\n",
    "                        c.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al'))                \n",
    "                    # M & L Services sheets\n",
    "                    if (i_s == 'M & L Services'):\n",
    "                        d.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al'))  \n",
    "                    # M & L industries sheets\n",
    "                    if (i_s == 'M & L industries'):\n",
    "                        e.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al')) \n",
    "                    # M & L Commerce sheets    \n",
    "                    if (i_s == 'M & L Commerce'):\n",
    "                        f.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al')) \n",
    "                    # Property Investment sheets    \n",
    "                    if (i_s == 'Property Investment'):\n",
    "                        g.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:AH')) \n",
    "                    # Property Development sheets \n",
    "                    if (i_s == 'Property Development'):\n",
    "                        h.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:AH')) \n",
    "                    # Hire purchase sheets \n",
    "                    if (i_s == 'Hire purchase'):\n",
    "                        i.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al')) \n",
    "                    # Co-operatives sheets \n",
    "                    if (i_s == 'Co-operatives'):\n",
    "                        j.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:AD')) \n",
    "                    # S services sheets \n",
    "                    if (i_s == 'S services'):\n",
    "                        k.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:AC')) \n",
    "                    # S Commerce sheets\n",
    "                    if (i_s == 'S Commerce'):\n",
    "                        l.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:AC')) \n",
    "                    # S industries sheets\n",
    "                    if (i_s == ' S industries'):\n",
    "                        m.append(pd.read_excel(i_f,sheet_name=i_s,usecols='A:AC')) \n",
    "    # Concatenate all data into one DataFrame\n",
    "    list_df = [a ,b ,c ,d ,e ,f ,g ,h ,i ,j ,k ,l ,m]\n",
    "    list_F = []\n",
    "    # for (i_x,i_y) in zip(list_df,list_T) :\n",
    "    for i_x in list_df:\n",
    "        i_x = pd.concat(i_x, ignore_index=True)\n",
    "        i_x.drop_duplicates(subset=['เลขที่ CIF' ,'วันที่ประเมิน' ,'Grade'],inplace=True)\n",
    "        i_x.dropna(how='all',inplace=True)\n",
    "        i_x.reset_index(inplace=True,drop=True) \n",
    "        list_F.append(i_x)\n",
    "    # for process on code\n",
    "    # list_F = tuple(list_F) \n",
    "    return list_F\n",
    "\n",
    "### for tag customer review CRR\n",
    "# add year follow requirement\n",
    "def check_fileCRR(path,year):\n",
    "    print('check start : {}'.format(year))\n",
    "    a = []\n",
    "    for i_p in path:\n",
    "        filenames = glob.glob(i_p + \"/*.xlsx\")\n",
    "        filenames\n",
    "        # for loop find name excel_sheets \n",
    "        for i_f in filenames:\n",
    "            if year in i_f or year == 'all':\n",
    "                xl = pd.ExcelFile(i_f)\n",
    "                for i_s in  xl.sheet_names:\n",
    "                 print('read file = {} ,sheet_name = {}'.format(i_f,i_s))\n",
    "                #  a.append(pd.read_excel(i_f,sheet_name=i_s,usecols=['บุคคล/นิติบุคคลที่ถูกประเมิน','เลขที่ CIF', 'วันที่ประเมิน','Grade','tool'],dtype={'เลขที่ CIF': str}))\n",
    "                #  a.append(pd.read_excel(i_f,sheet_name=i_s,usecols=['บุคคล/นิติบุคคลที่ถูกประเมิน','เลขที่ CIF','วัตถุประสงค์', 'วันที่ประเมิน','Grade','tool']))\n",
    "                # df = pd.read_excel(i_f,sheet_name=i_s,usecols=['บุคคล/นิติบุคคลที่ถูกประเมิน','เลขที่ CIF','วัตถุประสงค์' ,'วันที่ประเมิน','Grade'])\n",
    "                # df[['ประเภท']] = i_s\n",
    "                # a.append(df)\n",
    "                # เเก้ columns\n",
    "                 a.append(pd.read_excel(i_f,sheet_name=i_s,usecols=['บุคคล/นิติบุคคลที่ถูกประเมิน','เลขที่ CIF','วัตถุประสงค์', 'วันที่ประเมิน', 'Grade']))     \n",
    "    ### add concat file\n",
    "    a = pd.concat(a)  \n",
    "    a['เลขที่ CIF'] = a['เลขที่ CIF'].astype(str)\n",
    "    a.drop_duplicates(subset=['เลขที่ CIF' ,'วันที่ประเมิน' ,'Grade'],inplace=True)\n",
    "    a[['การจัดส่ง']] = 'ส่งเเล้ว'    \n",
    "    for i_c in a.columns:\n",
    "        a[i_c] = a[i_c].apply(lambda x: str(x).replace(u'\\xa0', u''))\n",
    "        a.reset_index(inplace=True,drop=True) \n",
    "    print('check complete : {}'.format(year))\n",
    "    return a\n",
    "\n",
    "def export_file(file,Name):\n",
    "        file.to_csv(output+'{}_{}.csv'.format(Name,dt.date.today().strftime(\"%y-%m-%d\")),index=False ,encoding='TIS-620')\n",
    "        return print('export complete')\n",
    "         \n",
    "def export_excel(list,Name,Folder):\n",
    "        tool_n = ['M & L Infrastructure','M & L Communication','M & L Energy','M & L Services'\n",
    "                  ,'M & L industries','M & L Commerce','Property Investment','Property Development'\n",
    "                  ,'Hire purchase','Co-operatives','S services','S Commerce','S industries']\n",
    "        with pd.ExcelWriter(Folder+'{}_{}.xlsx'.format(Name,dt.date.today().strftime(\"%y-%m-%d\"))) as writer: \n",
    "                for (i,n) in zip(list,tool_n):\n",
    "                        i.to_excel(writer, sheet_name=n,index=False,encoding='TIS-620')\n",
    "        print('export_complete')\n",
    "\n",
    "### for clean data\n",
    "def mappind_data(path):\n",
    "    map_date = pd.read_excel(os.path.join(mapping,'date_mapping.xlsx'))\n",
    "    map_grade = pd.read_excel(os.path.join(mapping,'grade_mapping.xlsx'))\n",
    "    map_CIF = pd.read_excel(os.path.join(mapping,'CIF_mapping.xlsx'))\n",
    "    map_CIF['เลขที่ CIF']= map_CIF['เลขที่ CIF'].astype(str)\n",
    "    map_date['วันที่ประเมิน']= map_date['วันที่ประเมิน'].astype(str)\n",
    "    # map_date = pd.read_csv(os.path.join(mapping,'date_mapping.csv'))\n",
    "    # map_grade = pd.read_csv(os.path.join(mapping,'grade_mapping.csv'))\n",
    "    # map_CIF = pd.read_csv(os.path.join(mapping,'CIF_mapping.csv'))\n",
    "    # map_CIF['เลขที่ CIF']= map_CIF['เลขที่ CIF'].astype(str)\n",
    "    # mutiple list in one line\n",
    "    # list_a, list_b = [], []\n",
    "    for i_p in path:\n",
    "        filenames = glob.glob(i_p + \"/*.xlsx\")\n",
    "        filenames\n",
    "        # for loop find name excel_sheets\n",
    "        for i_f in filenames:\n",
    "                xl = pd.ExcelFile(i_f)\n",
    "        # for loop read file and concat all file\n",
    "                for i_s in  xl.sheet_names:\n",
    "                    print('read file = {} ,sheet_name = {}'.format(i_f,i_s))\n",
    "                    # M & L Infrastructure sheets\n",
    "                    if (i_s == 'M & L Infrastructure'):\n",
    "                        # print(i_s,i_f)\n",
    "                        a = pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al')  \n",
    "                        a['tool'] = i_s             \n",
    "                    # M & L Communication sheets\n",
    "                    if (i_s == 'M & L Communication'):\n",
    "                        b = pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al') \n",
    "                        b['tool'] = i_s    \n",
    "                    # M & L Energy sheets\n",
    "                    if (i_s == 'M & L Energy'):\n",
    "                        c = pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al') \n",
    "                        c['tool'] = i_s              \n",
    "                    # M & L Services sheets\n",
    "                    if (i_s == 'M & L Services'):\n",
    "                        d = pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al') \n",
    "                        d['tool'] = i_s   \n",
    "                    # M & L industries sheets\n",
    "                    if (i_s == 'M & L industries'):\n",
    "                        e = pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al')\n",
    "                        e['tool'] = i_s \n",
    "                    # M & L Commerce sheets    \n",
    "                    if (i_s == 'M & L Commerce'):\n",
    "                        f = pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al')\n",
    "                        f['tool'] = i_s \n",
    "                    # Property Investment sheets    \n",
    "                    if (i_s == 'Property Investment'):\n",
    "                        g = pd.read_excel(i_f,sheet_name=i_s,usecols='A:AH')\n",
    "                        g['tool'] = i_s \n",
    "                    # Property Development sheets \n",
    "                    if (i_s == 'Property Development'):\n",
    "                        h = pd.read_excel(i_f,sheet_name=i_s,usecols='A:AH')\n",
    "                        h['tool'] = i_s\n",
    "                    # Hire purchase sheets \n",
    "                    if (i_s == 'Hire purchase'):\n",
    "                        i = pd.read_excel(i_f,sheet_name=i_s,usecols='A:Al')\n",
    "                        i['tool'] = i_s\n",
    "                    # Co-operatives sheets \n",
    "                    if (i_s == 'Co-operatives'):\n",
    "                        j = pd.read_excel(i_f,sheet_name=i_s,usecols='A:AD')\n",
    "                        j['tool'] = i_s\n",
    "                    # S services sheets \n",
    "                    if (i_s == 'S services'):\n",
    "                        k = pd.read_excel(i_f,sheet_name=i_s,usecols='A:AC')\n",
    "                        k['tool'] = i_s\n",
    "                    # S Commerce sheets\n",
    "                    if (i_s == 'S Commerce'):\n",
    "                        l = pd.read_excel(i_f,sheet_name=i_s,usecols='A:AC') \n",
    "                        l['tool'] = i_s\n",
    "                    # S industries sheets\n",
    "                    if (i_s == 'S industries'):\n",
    "                        m = pd.read_excel(i_f,sheet_name=i_s,usecols='A:AC') \n",
    "                        m['tool'] = i_s\n",
    "    # Concatenate all data into one DataFrame\n",
    "    list_df = [a ,b ,c ,d ,e ,f ,g ,h ,i ,j ,k ,l ,m]\n",
    "    list_F = []\n",
    "    # for (i_x,i_y) in zip(list_df,list_T) :\n",
    "    for i_x in list_df:\n",
    "        ### clean_date_data\n",
    "        i_x['วันที่ประเมิน']= i_x['วันที่ประเมิน'].astype(str)\n",
    "        i_x = i_x.merge(map_date, how='left' ,on ='วันที่ประเมิน' )\n",
    "        i_x[['วันที่ประเมิน']] = i_x[['วันที่ประเมิน_adjust']]\n",
    "        i_x.drop(columns=['วันที่ประเมิน_adjust'],inplace=True)\n",
    "        i_x['วันที่ประเมิน'] = i_x['วันที่ประเมิน'].dt.strftime('%Y-%m-%d')\n",
    "        i_x = i_x.merge(map_grade, how='left' ,on ='Grade' )\n",
    "        i_x[['Grade']] = i_x[['Grade_adjust']]\n",
    "        i_x.drop(columns=['Grade_adjust'],inplace=True)\n",
    "        i_x['เลขที่ CIF'] = i_x['เลขที่ CIF'].astype(str)\n",
    "        i_x = i_x.merge(map_CIF, how='left' ,on ='เลขที่ CIF' )\n",
    "        i_x[['เลขที่ CIF']] = i_x[['เลขที่ CIF_adjust']]\n",
    "        i_x.drop(columns=['เลขที่ CIF_adjust'],inplace=True)\n",
    "        i_x.drop_duplicates(subset=['เลขที่ CIF' ,'วันที่ประเมิน' ,'Grade'],inplace=True)\n",
    "        i_x.dropna(how='all',inplace=True)\n",
    "        i_x.reset_index(inplace=True,drop=True) \n",
    "        list_F.append(i_x)\n",
    "    # for process on code\n",
    "    # list_F = tuple(list_F) \n",
    "    return list_F\n",
    "\n",
    "def analize_sicr(df):\n",
    "    filenames = glob.glob(path_T9 + \"/*.txt\")[-1]\n",
    "    main = pd.read_csv(filenames,sep='|')\n",
    "    main = main[['OriginContractId','OriginCounterpartyId','StartDate','MaturityDate','ProductType','ProductSubtype']]\n",
    "    main.rename(columns={\"OriginCounterpartyId\": \"เลขที่ CIF\"},inplace=True)\n",
    "    main['เลขที่ CIF'] = main['เลขที่ CIF'].astype(str)\n",
    "    main.drop_duplicates(subset=['เลขที่ CIF'],inplace=True)\n",
    "    df = df[df['เลขที่ CIF'].str.contains(r'[0-9]')]\n",
    "    df = df[~df['เลขที่ CIF'].str.contains(r'/')]\n",
    "    df['เลขที่ CIF'] = df['เลขที่ CIF'].str.replace('.', '')\n",
    "    df['เลขที่ CIF'] =  df['เลขที่ CIF'].str[0:9].astype(int)\n",
    "    df['เลขที่ CIF'] = df['เลขที่ CIF'].astype(str)\n",
    "    # df.drop(columns=['การจัดส่ง'],inplace = True)\n",
    "    df_current = []\n",
    "    df_originate = []\n",
    "    df['วันที่ประเมิน'] = pd.to_datetime(df['วันที่ประเมิน'], format='%Y-%m-%d')\n",
    "    CIF = df['เลขที่ CIF'].unique()\n",
    "    for i in CIF:\n",
    "        df_i = df[df['เลขที่ CIF'].isin([i])]\n",
    "        df_i = df_i.iloc[:,0:5]\n",
    "        originate = df_i.iloc[df_i[\"วันที่ประเมิน\"].argmin()]\n",
    "        df_originate.append(originate)\n",
    "        current = df_i.iloc[df_i[\"วันที่ประเมิน\"].argmax()]\n",
    "        df_current.append(current)\n",
    "    df_originate = pd.DataFrame(df_originate)\n",
    "    df_originate.rename(columns={'บุคคล/นิติบุคคลที่ถูกประเมิน':'บุคคล/นิติบุคคลที่ถูกประเมิน_originate',\"วันที่ประเมิน\": \"วันที่ประเมิน_originate\", \"Grade\": \"Grade_originate\",'tool':'tool_originate','วัตถุประสงค์':'วัตถุประสงค์_originate'},inplace=True)\n",
    "    main = main.merge(df_originate,how='left' ,on ='เลขที่ CIF')\n",
    "    main.drop_duplicates(subset=['เลขที่ CIF'],inplace=True)\n",
    "    df_current = pd.DataFrame(df_current)\n",
    "    df_current.rename(columns={'บุคคล/นิติบุคคลที่ถูกประเมิน':'บุคคล/นิติบุคคลที่ถูกประเมิน_current',\"วันที่ประเมิน\": \"วันที่ประเมิน_current\", \"Grade\": \"Grade_current\",'tool':'tool_current','วัตถุประสงค์':'วัตถุประสงค์_current'},inplace=True)\n",
    "    main = main.merge(df_current,how='left' ,on ='เลขที่ CIF')\n",
    "    main = main[main['เลขที่ CIF'].str.contains(r'[0-9]')]\n",
    "    main = main[~main['เลขที่ CIF'].str.contains(r'/')]\n",
    "    main['เลขที่ CIF'] = main['เลขที่ CIF'].str.replace('.', '')\n",
    "    main['เลขที่ CIF'] =  main['เลขที่ CIF'].str[0:9].astype(int)\n",
    "    main.drop_duplicates(subset=['เลขที่ CIF'],inplace=True)\n",
    "    return main\n",
    "\n",
    "# def map_performance(df):\n",
    "#     filenames = glob.glob(cbs_performance + \"/*.csv\")\n",
    "#     for i in filenames:\n",
    "#         print('start read file {}'.format(i[36:44]))\n",
    "#         df_p = pd.read_csv(i)\n",
    "#         df_p = df_p[['Customer Number','PF/NPF Flag']]\n",
    "#         df_p.rename(columns={\"PF/NPF Flag\": \"PF/NPF Flag{}\".format(i[36:44])},inplace=True)\n",
    "#         df_p.drop_duplicates(subset='Customer Number',inplace=True)\n",
    "#         df = df.merge(df_p,on='Customer Number',how='left')\n",
    "#     return df\n",
    "\n",
    "def define_GB(df):\n",
    "    list_GB = []\n",
    "    list_CIF = df['CUST_ID'].unique()\n",
    "    filenames = glob.glob(cbs_performance + \"/*.txt\")[-1]\n",
    "    df_p = pd.read_csv(filenames,sep='\\t')\n",
    "    print('start replace date format....')\n",
    "    list_date = {'31 ธ.ค.  2021':'2021-12-31', '30 พ.ย.  2021':'2021-11-30', '31 ต.ค.  2021':'2021-10-31', '30 ก.ย.  2021':'2021-09-30',\n",
    "       '31 ส.ค.  2021':'2021-08-31', '31 ก.ค.  2021':'2021-07-31', '30 มิ.ย. 2021':'2021-06-30', '31 พ.ค.  2021':'2021-05-31',\n",
    "       '30 เม.ย. 2021':'2021-04-30', '31 ม.ค.  2020':'2020-01-31', '29 ก.พ.  2020':'2020-02-29', '31 มี.ค. 2020':'2020-03-31',\n",
    "       '30 เม.ย. 2020':'2020-04-30', '31 พ.ค.  2020':'2020-05-31', '30 มิ.ย. 2020':'2020-06-30', '31 ก.ค.  2020':'2020-07-31',\n",
    "       '31 ส.ค.  2020':'2020-08-31', '30 ก.ย.  2020':'2020-09-30', '31 ต.ค.  2020':'2020-10-31', '30 พ.ย.  2020':'2020-11-30',\n",
    "       '31 ธ.ค.  2020':'2020-12-31', '31 ม.ค.  2021':'2021-01-31', '28 ก.พ.  2021':'2021-02-28', '31 มี.ค. 2021':'2021-03-31',\n",
    "       '28 ก.พ.  2022':'2022-02-28', '31 ม.ค.  2022':'2022-01-31', '31 ม.ค.  2023':'2023-01-31', '31 มี.ค. 2022':'2022-03-31',\n",
    "       '31 ธ.ค.  2022':'2022-12-31', '31 พ.ค.  2022':'2022-05-31', '30 มิ.ย. 2022':'2022-06-30', '31 ก.ค.  2022':'2022-07-31',\n",
    "       '31 ส.ค.  2022':'2022-08-31', '30 ก.ย.  2022':'2022-09-30', '30 เม.ย. 2022':'2022-04-30', '31 ต.ค.  2022':'2022-10-31',\n",
    "       '30 พ.ย.  2022':'2022-11-30', '28 ก.พ.  2023':'2023-02-28', '31 มี.ค. 2023':'2023-03-31', '30 เม.ย. 2023':'2023-04-30',\n",
    "       '31 พ.ค.  2023':'2023-05-31', '30 มิ.ย. 2023':'2021-06-30', '30 ก.ย.  2023':'2023-09-30', '31 ส.ค.  2023':'2023-08-31',\n",
    "       '31 ก.ค.  2023':'2023-07-31', '31 ต.ค.  2023':'2023-10-31', '30 พ.ย.  2023':'2023-11-30'}\n",
    "    df_p['AS_OF_DATE'].replace(list_date,inplace=True)\n",
    "    df_p['AS_OF_DATE'] = pd.to_datetime(df_p['AS_OF_DATE'])\n",
    "    df_p.fillna({'NPF_FLAG':'N'}, inplace=True)\n",
    "    df_p['NPF_count'] = df_p['NPF_FLAG'].apply(lambda x : 1 if x =='Y' else 0)\n",
    "    # df.rename(columns={'Customer Number': \"CUST_ID\"},inplace=True)\n",
    "    df['วันที่ประเมิน_originate'] = pd.to_datetime(df['วันที่ประเมิน_originate'])\n",
    "    df_p.drop_duplicates(subset=['CUST_ID','AS_OF_DATE'],inplace=True)\n",
    "    print('........start Flag G/B.........')\n",
    "    for i in list_CIF:\n",
    "        df_1 = df_p[df_p['CUST_ID'].isin([i])]\n",
    "        df_2 = df[df['CUST_ID'].isin([i])]\n",
    "        df_3 = df_1[df_1['AS_OF_DATE'] >= df_2['วันที่ประเมิน_originate'].unique()[0]]\n",
    "        df_3['วันที่ประเมิน_originate'] = df_2['วันที่ประเมิน_originate']\n",
    "        df_3['Months'] = df_3['AS_OF_DATE'].dt.to_period('M').astype('int64') - df_3['วันที่ประเมิน_originate'].dt.to_period('M').astype('int64')\n",
    "        list_GB.append(df_3)\n",
    "    df_GB = pd.concat(list_GB)\n",
    "    df_GB = df_GB[['CUST_ID','NPF_count']].groupby('CUST_ID').sum()\n",
    "    df_GB['GB_flag'] = df_GB['NPF_count'].apply(lambda x :'Bad' if x>0 else 'Good')\n",
    "    print('........End process....')\n",
    "    return df_GB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final CRR data for sicr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check start : all\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = M & L Infrastructure\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = M & L Communication\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = M & L Energy\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = M & L Services\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = M & L industries\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = M & L Commerce\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = Property Investment\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = Property Development\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = Hire purchase\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = Co-operatives\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = S services\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = S Commerce\n",
      "read file = data_revised\\ALL_CRR_24-01-10.xlsx ,sheet_name = S industries\n",
      "check complete : all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\630039\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3338: DtypeWarning: Columns (3,4,9,10,17,18,34,35,36,41,44,61,70) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'พง1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-99033789e9f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# data.drop(columns='การจัดส่ง',inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# data.to_excel(os.path.join(output,'CRR_file_for_sicr.xlsx'),index=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mCRR_SICR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalize_sicr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mCRR_SICR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CRR_SICR_final_v3.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-7b617436b748>\u001b[0m in \u001b[0;36manalize_sicr\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'เลขที่ CIF'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'เลขที่ CIF'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'เลขที่ CIF'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'เลขที่ CIF'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'เลขที่ CIF'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'เลขที่ CIF'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'เลขที่ CIF'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;31m# df.drop(columns=['การจัดส่ง'],inplace = True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\630039\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5544\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5545\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5546\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5547\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\630039\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     ) -> \"BlockManager\":\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m     def convert(\n",
      "\u001b[1;32mc:\\Users\\630039\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\630039\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    593\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\630039\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    970\u001b[0m         \u001b[1;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[1;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'พง1'"
     ]
    }
   ],
   "source": [
    "all_path = [data_revised]\n",
    "data = check_fileCRR(all_path,'all')\n",
    "# data.drop(columns='การจัดส่ง',inplace=True)\n",
    "# data.to_excel(os.path.join(output,'CRR_file_for_sicr.xlsx'),index=False)\n",
    "CRR_SICR = analize_sicr(data)\n",
    "CRR_SICR.to_excel(os.path.join(output,'CRR_SICR_final_v3.xlsx'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test before fnction ### example information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC_ID</th>\n",
       "      <th>PROD_TYPE</th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>BRANCH_CODE</th>\n",
       "      <th>CREDIT_LIMIT</th>\n",
       "      <th>LEDGER_BALANCE</th>\n",
       "      <th>ACC_CLASS</th>\n",
       "      <th>ISIC_NEW_FINAL_BY_OIS</th>\n",
       "      <th>ISIC_GROUP_NEW_BY_OIS</th>\n",
       "      <th>ACC_OPEN_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>DEALER_CODE</th>\n",
       "      <th>ISIC_NEW_FINAL</th>\n",
       "      <th>ISIC_13GROUP</th>\n",
       "      <th>ISIC_5GROUP</th>\n",
       "      <th>NEW_SIZE_FLAG</th>\n",
       "      <th>PROF_DIV_RATE</th>\n",
       "      <th>RESTRUCTURE_FLAG</th>\n",
       "      <th>LOAN_PAYMENT_HOLIDAY</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "      <th>AS_OF_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244218</th>\n",
       "      <td>89304926.0</td>\n",
       "      <td>8200</td>\n",
       "      <td>380000938</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F439020</td>\n",
       "      <td>F</td>\n",
       "      <td>23 ก.ย.  2021</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31 ธ.ค.  2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244219</th>\n",
       "      <td>89307968.0</td>\n",
       "      <td>8200</td>\n",
       "      <td>380000938</td>\n",
       "      <td>8</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F439020</td>\n",
       "      <td>F</td>\n",
       "      <td>09 พ.ย.  2021</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31 ธ.ค.  2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244220</th>\n",
       "      <td>89307895.0</td>\n",
       "      <td>8200</td>\n",
       "      <td>380000938</td>\n",
       "      <td>8</td>\n",
       "      <td>8521765.0</td>\n",
       "      <td>6747883.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F439020</td>\n",
       "      <td>F</td>\n",
       "      <td>27 ต.ค.  2021</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31 ธ.ค.  2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244221</th>\n",
       "      <td>89307887.0</td>\n",
       "      <td>8200</td>\n",
       "      <td>380000938</td>\n",
       "      <td>8</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F439020</td>\n",
       "      <td>F</td>\n",
       "      <td>27 ต.ค.  2021</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31 ธ.ค.  2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244222</th>\n",
       "      <td>89307811.0</td>\n",
       "      <td>8200</td>\n",
       "      <td>380000938</td>\n",
       "      <td>8</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F439020</td>\n",
       "      <td>F</td>\n",
       "      <td>21 ต.ค.  2021</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31 ธ.ค.  2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159502</th>\n",
       "      <td>89319842.0</td>\n",
       "      <td>8200</td>\n",
       "      <td>380000938</td>\n",
       "      <td>8</td>\n",
       "      <td>1947755.0</td>\n",
       "      <td>1947755.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F439020</td>\n",
       "      <td>F</td>\n",
       "      <td>14 พ.ย.  2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30 พ.ย.  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159503</th>\n",
       "      <td>89318765.0</td>\n",
       "      <td>8200</td>\n",
       "      <td>380000938</td>\n",
       "      <td>8</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F439020</td>\n",
       "      <td>F</td>\n",
       "      <td>08 ก.ย.  2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30 พ.ย.  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159504</th>\n",
       "      <td>89319141.0</td>\n",
       "      <td>8200</td>\n",
       "      <td>380000938</td>\n",
       "      <td>8</td>\n",
       "      <td>4621920.0</td>\n",
       "      <td>4621920.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F439020</td>\n",
       "      <td>F</td>\n",
       "      <td>04 ต.ค.  2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30 พ.ย.  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159505</th>\n",
       "      <td>89319133.0</td>\n",
       "      <td>8200</td>\n",
       "      <td>380000938</td>\n",
       "      <td>8</td>\n",
       "      <td>3655780.0</td>\n",
       "      <td>3655780.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F439020</td>\n",
       "      <td>F</td>\n",
       "      <td>04 ต.ค.  2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30 พ.ย.  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159506</th>\n",
       "      <td>89319516.0</td>\n",
       "      <td>8200</td>\n",
       "      <td>380000938</td>\n",
       "      <td>8</td>\n",
       "      <td>7500000.0</td>\n",
       "      <td>7500000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F439020</td>\n",
       "      <td>F</td>\n",
       "      <td>24 ต.ค.  2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30 พ.ย.  2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ACC_ID  PROD_TYPE    CUST_ID  BRANCH_CODE  CREDIT_LIMIT  \\\n",
       "244218   89304926.0       8200  380000938            8    10000000.0   \n",
       "244219   89307968.0       8200  380000938            8     6000000.0   \n",
       "244220   89307895.0       8200  380000938            8     8521765.0   \n",
       "244221   89307887.0       8200  380000938            8    10000000.0   \n",
       "244222   89307811.0       8200  380000938            8    30000000.0   \n",
       "...             ...        ...        ...          ...           ...   \n",
       "3159502  89319842.0       8200  380000938            8     1947755.0   \n",
       "3159503  89318765.0       8200  380000938            8    20000000.0   \n",
       "3159504  89319141.0       8200  380000938            8     4621920.0   \n",
       "3159505  89319133.0       8200  380000938            8     3655780.0   \n",
       "3159506  89319516.0       8200  380000938            8     7500000.0   \n",
       "\n",
       "         LEDGER_BALANCE  ACC_CLASS ISIC_NEW_FINAL_BY_OIS  \\\n",
       "244218       10000000.0        1.0               F439020   \n",
       "244219        6000000.0        1.0               F439020   \n",
       "244220        6747883.0        1.0               F439020   \n",
       "244221       10000000.0        1.0               F439020   \n",
       "244222       30000000.0        1.0               F439020   \n",
       "...                 ...        ...                   ...   \n",
       "3159502       1947755.0        1.0               F439020   \n",
       "3159503      20000000.0        1.0               F439020   \n",
       "3159504       4621920.0        1.0               F439020   \n",
       "3159505       3655780.0        1.0               F439020   \n",
       "3159506       7500000.0        1.0               F439020   \n",
       "\n",
       "        ISIC_GROUP_NEW_BY_OIS  ACC_OPEN_DATE  ... DEALER_CODE  ISIC_NEW_FINAL  \\\n",
       "244218                      F  23 ก.ย.  2021  ...         NaN             NaN   \n",
       "244219                      F  09 พ.ย.  2021  ...         NaN             NaN   \n",
       "244220                      F  27 ต.ค.  2021  ...         NaN             NaN   \n",
       "244221                      F  27 ต.ค.  2021  ...         NaN             NaN   \n",
       "244222                      F  21 ต.ค.  2021  ...         NaN             NaN   \n",
       "...                       ...            ...  ...         ...             ...   \n",
       "3159502                     F  14 พ.ย.  2023  ...         NaN             NaN   \n",
       "3159503                     F  08 ก.ย.  2023  ...         NaN             NaN   \n",
       "3159504                     F  04 ต.ค.  2023  ...         NaN             NaN   \n",
       "3159505                     F  04 ต.ค.  2023  ...         NaN             NaN   \n",
       "3159506                     F  24 ต.ค.  2023  ...         NaN             NaN   \n",
       "\n",
       "         ISIC_13GROUP  ISIC_5GROUP NEW_SIZE_FLAG PROF_DIV_RATE  \\\n",
       "244218            NaN          NaN             3          6.53   \n",
       "244219            NaN          NaN             3          6.53   \n",
       "244220            NaN          NaN             3          6.53   \n",
       "244221            NaN          NaN             3          6.53   \n",
       "244222            NaN          NaN             3          6.53   \n",
       "...               ...          ...           ...           ...   \n",
       "3159502           NaN          NaN             3          7.25   \n",
       "3159503           NaN          NaN             3          7.25   \n",
       "3159504           NaN          NaN             3          7.25   \n",
       "3159505           NaN          NaN             3          7.25   \n",
       "3159506           NaN          NaN             3          7.25   \n",
       "\n",
       "         RESTRUCTURE_FLAG  LOAN_PAYMENT_HOLIDAY  DATA_SOURCE     AS_OF_DATE  \n",
       "244218                0.0                   0.0            1  31 ธ.ค.  2021  \n",
       "244219                0.0                   0.0            1  31 ธ.ค.  2021  \n",
       "244220                0.0                   0.0            1  31 ธ.ค.  2021  \n",
       "244221                0.0                   0.0            1  31 ธ.ค.  2021  \n",
       "244222                0.0                   0.0            1  31 ธ.ค.  2021  \n",
       "...                   ...                   ...          ...            ...  \n",
       "3159502               0.0                   0.0            1  30 พ.ย.  2023  \n",
       "3159503               0.0                   0.0            1  30 พ.ย.  2023  \n",
       "3159504               0.0                   0.0            1  30 พ.ย.  2023  \n",
       "3159505               0.0                   0.0            1  30 พ.ย.  2023  \n",
       "3159506               0.0                   0.0            1  30 พ.ย.  2023  \n",
       "\n",
       "[320 rows x 40 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p[df_p['CUST_ID'] == 380000938]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex = pd.read_excel('backup\\CRR_SICR_เเก้ไขส่งให้พี่เคี้ยง.xlsx')\n",
    "df_ex = df_ex.dropna(subset=['วันที่ประเมิน_originate'])\n",
    "df_ex = df_ex.dropna(subset=['CUST_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>NPF_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB_flag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  CUST_ID  NPF_count\n",
       "GB_flag                           \n",
       "Bad         85       85         85\n",
       "Good       790      790        790"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = define_GB(df_ex)\n",
    "# test.reset_index(inplace=True)\n",
    "test.groupby('GB_flag').count()\n",
    "# test.duplicated(subset='CUST_ID').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f = df_ex.merge(test,on='CUST_ID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f.to_excel(os.path.join(output,'sample_data.xlsx'),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
